{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this task is to create the \"Word rating\" program. \n",
    "\n",
    "You have to print the TOP-10 most popular words in the input dataset. The words list is in `/data/wiki/en_articles_part` file. \n",
    "\n",
    "There are several points for this task:\n",
    "\n",
    "1) You have to print data only at the end. The criteria is if you have received first empty rdd, the stream is finished. At this moment you have to print the result and stop the context.\n",
    "\n",
    "2) You may split the line, using $flatMap$ method in StreamingContext.queueStream.\n",
    "\n",
    "3) In this task we are working with the words that have lengths greater than 3. For this aim you may use $filter$ method in StreamingContext.queueStream.\n",
    "\n",
    "4) Remember about letter lower case. You may use $map$ method in StreamingContext.queueStream.\n",
    "\n",
    "Here you can find the draft for the main steps of the task. You can use other methods to get the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing SparkContext\n",
    "sc = SparkContext(master='local[4]')\n",
    "\n",
    "# Preparing base RDD with the input data\n",
    "DATA_PATH = \"/data/wiki/en_articles_part\"\n",
    "\n",
    "batches = [sc.textFile(os.path.join(DATA_PATH, path)) for path in os.listdir(DATA_PATH)]\n",
    "\n",
    "# Creating QueueStream to emulate realtime data generating\n",
    "BATCH_TIMEOUT = 5  # Timeout between batch generation\n",
    "ssc = StreamingContext(sc, BATCH_TIMEOUT)\n",
    "dstream = ssc.queueStream(rdds=batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished = False\n",
    "printed = False\n",
    "\n",
    "\n",
    "def set_ending_flag(rdd):\n",
    "    global finished\n",
    "    if rdd.isEmpty():\n",
    "        finished = True\n",
    "\n",
    "\n",
    "def print_only_at_the_end(rdd):\n",
    "    global printed\n",
    "    if finished and not printed:\n",
    "        # Type your code for printing sorted data from stream in loop\n",
    "        \n",
    "        printed = True\n",
    "\n",
    "\n",
    "# If we have received empty rdd, the stream is finished.\n",
    "# So print the result and stop the context.\n",
    "dstream.foreachRDD(set_ending_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code for data processing and aggregation here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.checkpoint('./checkpoint')  # checkpoint for storing current state        \n",
    "ssc.start()\n",
    "while not printed:\n",
    "    pass\n",
    "ssc.stop()\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
